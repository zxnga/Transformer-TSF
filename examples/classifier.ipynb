{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import Dataset\n",
    "from functools import partial\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction\n",
    "\n",
    "from src.utils import transform_start_field\n",
    "from src import ts_transformer as tsf\n",
    "from src.inference.wrapper import TFWrapper\n",
    "from src.ts_transformer import create_train_dataloader\n",
    "\n",
    "from src.networks.classifier import RepresentationClassifier, train_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assumes a dataset <data>\n",
    "\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a pretrained model, for training check train_test.ipynb\n",
    "\n",
    "freq = '1H'\n",
    "transformer = TimeSeriesTransformerForPrediction.from_pretrained(\n",
    "    \"<PATH_TO_WEIGHTS>\")\n",
    "model = TFWrapper(transformer, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. forward pass of all data in trained transformer\n",
    "2. extract latent space\n",
    "3. add corresponding label\n",
    "4. Jointly train projection network and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "train_data.set_transform(partial(transform_start_field, freq=freq))\n",
    "\n",
    "valid_data = Dataset.from_pandas(valid_df, preserve_index=False)\n",
    "valid_data.set_transform(partial(transform_start_field, freq=freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = create_train_dataloader(\n",
    "                            config=model.model_config,\n",
    "                            freq=model.freq,\n",
    "                            data=train_data,\n",
    "                            batch_size=32,\n",
    "                            num_batches_per_epoch=16)\n",
    "\n",
    "valid_dataloader = create_train_dataloader(\n",
    "                            config=model.model_config,\n",
    "                            freq=model.freq,\n",
    "                            data=valid_data,\n",
    "                            batch_size=32,\n",
    "                            num_batches_per_epoch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "# we classify the first static feature\n",
    "num_classes = len(list(set([i[0] for i in train_df['feat_static_cat']])))\n",
    "\n",
    "classifier = RepresentationClassifier(\n",
    "    encoder_hidden_size=model.model_config.d_model,\n",
    "    attn_hidden_dims= None, #[64, 32],\n",
    "    classifier_hidden_dims= None, #[64, 32],\n",
    "    num_classes=num_classes,\n",
    "    attn_activation=nn.Tanh,\n",
    "    classifier_activation=nn.ReLU,\n",
    "    attn_dropout=0,\n",
    "    classifier_dropout=0,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier, train_losses, valid_losses = train_classifier(\n",
    "    model=model.transformer,\n",
    "    classifier=classifier,\n",
    "    train_loader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=model.transformer.device,\n",
    "    num_epochs=num_epochs,\n",
    "    valid_loader=valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_losses, label='Classifier Training Loss')\n",
    "plt.plot(valid_losses, label='Classifier Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".tsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
